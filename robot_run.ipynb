{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from maze_env import Maze\n",
    "from utility import RL\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def onKeyPress(event):\n",
    "#     is_terminate = False\n",
    "#     if (event.char == \"w\"):\n",
    "#         is_terminate, reward = env.take_action(0, show_animate=True)\n",
    "#     elif (event.char == \"d\"):\n",
    "#         is_terminate, reward = env.take_action(1, show_animate=True)\n",
    "#     elif (event.char == \"s\"):\n",
    "#         is_terminate, reward = env.take_action(2, show_animate=True)\n",
    "#     elif (event.char == \"a\"):\n",
    "#         is_terminate, reward = env.take_action(3, show_animate=True)\n",
    "#     elif (event.char == \"q\"):\n",
    "#         env.destroy()\n",
    "#     if (is_terminate):\n",
    "#         env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4x4, act_space = 4\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "env = Maze()\n",
    "rl = RL(env)\n",
    "print('{0}x{1}, act_space = {2}'.format(env.MAZE_Limit[0],env.MAZE_Limit[1], len(env.action_space)))\n",
    "# env.bind('<KeyPress>', onKeyPress)\n",
    "# env.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DP Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 [[ 0. -1. -2. -3.]\n",
      " [-1. -2.  0. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "rl.DP.iteration(update = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model-free MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is MC\n"
     ]
    }
   ],
   "source": [
    "rl.MF.iteration(n_episode = 3000,  model = \"MC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Expect] State-value\n",
      " [[ 0.         -5.06419824 -6.87033052 -7.30079733]\n",
      " [-5.0930815  -6.33360063  0.         -6.8884636 ]\n",
      " [-7.03745436 -6.99597666 -6.236216   -5.05161999]\n",
      " [-7.55059119 -6.97033549 -5.12569322  0.        ]]\n",
      "[Max] Action to State-value\n",
      " [[ 0.         -1.         -5.65364303 -7.02999837]\n",
      " [-1.         -5.60460782  0.         -5.4671332 ]\n",
      " [-5.69219769 -6.60886073 -5.56379339 -1.        ]\n",
      " [-7.29583771 -5.6028993  -1.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "Avalue = rl.MF.Avalue\n",
    "final_policy = rl.MF.policy\n",
    "print(\"[Expect] State-value\\n\",np.sum(final_policy*Avalue, axis=0).reshape(env.MAZE_Limit[0],env.MAZE_Limit[1]))\n",
    "print(\"[Max] Action to State-value\\n\",np.max(Avalue,axis=0).reshape(env.MAZE_Limit[0],env.MAZE_Limit[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model-free TD(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameters\n",
    "rl.MF.gamma = 0.9 # discount factor\n",
    "rl.MF.lamb = 0.9 # parameter of sarsa\n",
    "rl.MF.alpha = 0.5 # step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is TD_0\n"
     ]
    }
   ],
   "source": [
    "rl.MF.iteration(n_episode = 3000,  model = \"TD_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Expect] State-value\n",
      " [[  0.     -7.75   -7.975  -6.355]\n",
      " [ -7.75  -10.      0.     -7.975]\n",
      " [ -7.975 -10.    -10.     -7.75 ]\n",
      " [ -6.355  -7.975  -7.75    0.   ]]\n",
      "[Max] Action to State-value\n",
      " [[  0.    -1.    -1.9   -2.71]\n",
      " [ -1.   -10.     0.    -1.9 ]\n",
      " [ -1.9  -10.   -10.    -1.  ]\n",
      " [ -2.71  -1.9   -1.     0.  ]]\n"
     ]
    }
   ],
   "source": [
    "Avalue = rl.MF.Avalue\n",
    "print(\"[Expect] State-value\\n\",np.sum(final_policy*Avalue, axis=0).reshape(env.MAZE_Limit[1],env.MAZE_Limit[0]))\n",
    "print(\"[Max] Action to State-value\\n\",np.max(Avalue,axis=0).reshape(env.MAZE_Limit[1],env.MAZE_Limit[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model-free TD(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is TD_n\n"
     ]
    }
   ],
   "source": [
    "rl.MF.iteration(n_episode = 3000,  model = \"TD_n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Expect] State-value\n",
      " [[ 0.         -4.82790569 -7.15798409 -7.03026271]\n",
      " [-5.81728287 -6.12045627  0.         -6.44420516]\n",
      " [-7.5350811  -6.17118395 -5.76243384 -5.33528647]\n",
      " [-7.14822229 -6.81877635 -4.49658247  0.        ]]\n",
      "[Max] Action to State-value\n",
      " [[ 0.         -1.         -4.49787414 -5.59535308]\n",
      " [-1.         -4.10768668  0.         -4.89757636]\n",
      " [-6.44725977 -4.74981201 -3.6859133  -1.        ]\n",
      " [-6.39123152 -3.63486322 -1.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "Avalue = rl.MF.Avalue\n",
    "print(\"[Expect] State-value\\n\",np.sum(final_policy*Avalue, axis=0).reshape(env.MAZE_Limit[1],env.MAZE_Limit[0]))\n",
    "print(\"[Max] Action to State-value\\n\",np.max(Avalue,axis=0).reshape(env.MAZE_Limit[1],env.MAZE_Limit[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model-free TD(lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is TD_lambda\n"
     ]
    }
   ],
   "source": [
    "rl.MF.iteration(n_episode = 1000,  model = \"TD_lambda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Expect] State-value\n",
      " [[  0.          -7.7500723   -7.97510877  -6.35506829]\n",
      " [ -7.74995085 -10.00024007   0.          -7.97469045]\n",
      " [ -7.97445178  -9.99973195  -9.99950401  -7.74977264]\n",
      " [ -6.35496893  -7.97529965  -7.75019705   0.        ]]\n",
      "[Max] Action to State-value\n",
      " [[ 0.         -1.         -1.90000732 -2.70993973]\n",
      " [-1.         -9.99982572  0.         -1.90013046]\n",
      " [-1.89999096 -9.99820752 -9.99808822 -1.        ]\n",
      " [-2.7098692  -1.89998324 -1.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "Avalue = rl.MF.Avalue\n",
    "print(\"[Expect] State-value\\n\",np.sum(final_policy*Avalue, axis=0).reshape(env.MAZE_Limit[1],env.MAZE_Limit[0]))\n",
    "print(\"[Max] Action to State-value\\n\",np.max(Avalue,axis=0).reshape(env.MAZE_Limit[1],env.MAZE_Limit[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model-free Control MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is MC\n"
     ]
    }
   ],
   "source": [
    "rl.MF.iteration(n_episode = 3000,  model = \"MC\", control = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Expect] State-value\n",
      " [[ 0.         -1.9458272  -3.59381186 -4.42146576]\n",
      " [-1.95964657 -3.23000444  0.         -3.35976955]\n",
      " [-3.38394308 -3.88066404 -3.13506266 -1.95379218]\n",
      " [-4.26116157 -3.38337464 -1.95408934  0.        ]]\n",
      "[Max] Action to State-value\n",
      " [[ 0.         -1.         -2.81241376 -4.05163105]\n",
      " [-1.         -2.83499715  0.         -2.77872967]\n",
      " [-2.71381137 -3.80841631 -2.77603983 -1.        ]\n",
      " [-4.03985869 -2.69834365 -1.          0.        ]]\n",
      "Policy\n",
      " [[0 3 3 3]\n",
      " [0 0 0 2]\n",
      " [0 1 1 2]\n",
      " [0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "Avalue = rl.MF.Avalue\n",
    "final_policy = rl.MF.policy\n",
    "print(\"[Expect] State-value\\n\",np.sum(final_policy*Avalue, axis=0).reshape(env.MAZE_Limit[1],env.MAZE_Limit[0]))\n",
    "print(\"[Max] Action to State-value\\n\",np.max(Avalue,axis=0).reshape(env.MAZE_Limit[1],env.MAZE_Limit[0]))\n",
    "print(\"Policy\\n\",np.argmax(final_policy,axis=0).reshape(env.MAZE_Limit[1],env.MAZE_Limit[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model-free Control Sarsa(lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is TD_lambda\n"
     ]
    }
   ],
   "source": [
    "rl.MF.iteration(n_episode = 30000,  model = \"TD_lambda\", control = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Expect] State-value\n",
      " [[  0.          -4.35593318  -4.92463708  -4.46907521]\n",
      " [ -4.37574753 -10.00271447   0.          -4.91395736]\n",
      " [ -4.93737937 -10.00139913  -9.99968137  -4.33915167]\n",
      " [ -4.53238164  -4.93911043  -4.37495103   0.        ]]\n",
      "[Max] Action to State-value\n",
      " [[ 0.         -1.         -1.89948633 -2.70936706]\n",
      " [-1.         -9.99999667  0.         -1.89898173]\n",
      " [-1.89990822 -9.99939441 -9.99922115 -1.        ]\n",
      " [-2.70988597 -1.89999476 -1.          0.        ]]\n",
      "Policy\n",
      " [[0 3 3 3]\n",
      " [0 3 0 2]\n",
      " [0 3 3 2]\n",
      " [1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "Avalue = rl.MF.Avalue\n",
    "final_policy = rl.MF.policy\n",
    "print(\"[Expect] State-value\\n\",np.sum(final_policy*Avalue, axis=0).reshape(env.MAZE_Limit[1],env.MAZE_Limit[0]))\n",
    "print(\"[Max] Action to State-value\\n\",np.max(Avalue,axis=0).reshape(env.MAZE_Limit[1],env.MAZE_Limit[0]))\n",
    "print(\"Policy\\n\",np.argmax(final_policy,axis=0).reshape(env.MAZE_Limit[1],env.MAZE_Limit[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "a = np.array([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  4.,  8., 16.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t = time.time()\n",
    "np.logspace(start=1,stop=len(a),num=len(a),endpoint=True,base=2)/2\n",
    "# print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  4,  8, 16])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t = time.time()\n",
    "np.array([2**i for i in range(len(a))])\n",
    "# print(time.time()-t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
